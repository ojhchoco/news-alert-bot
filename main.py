from fastapi import FastAPI, Query, Body, HTTPException, Request
from fastapi.responses import HTMLResponse
from starlette.templating import Jinja2Templates
from typing import List, Optional, Tuple, Dict, Literal
from pydantic import BaseModel, Field
import re
from collections import Counter
import os
import logging
from datetime import datetime, timedelta
import requests
from dotenv import load_dotenv
import pytz
import xml.etree.ElementTree as ET

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

# Google News RSS ê¸°ë³¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì¬ì •ì˜ ê°€ëŠ¥)
GOOGLE_NEWS_HL = os.getenv("GOOGLE_NEWS_HL", "ko")      # UI ì–¸ì–´
GOOGLE_NEWS_GL = os.getenv("GOOGLE_NEWS_GL", "KR")      # êµ­ê°€ ì½”ë“œ
GOOGLE_NEWS_CEID = os.getenv("GOOGLE_NEWS_CEID", "KR:ko")

# Google Custom Search (ì—°êµ¬/ì •ë¶€ ìë£Œìš©)
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID")  # ì»¤ìŠ¤í…€ ê²€ìƒ‰ ì—”ì§„ ID
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")  # Google API í‚¤

app = FastAPI(title="ë‰´ìŠ¤ ê²€ìƒ‰ ë° Slack ì•Œë¦¼ ì‹œìŠ¤í…œ")

# Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")


class NewsItem(BaseModel):
    title: str
    keyword: str


class NewsResponse(BaseModel):
    keyword: str
    news: List[NewsItem]


class TextRequest(BaseModel):
    text: str


class KeywordResponse(BaseModel):
    keywords: List[str]
    count: int


class NewsSearchItem(BaseModel):
    title: str
    link: str
    pubDate: str
    keyword: Optional[str] = Field(None, description="ì´ ê¸°ì‚¬ê°€ ê²€ìƒ‰ëœ í‚¤ì›Œë“œ (ì—¬ëŸ¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ í‘œì‹œ)")


class NewsSearchRequest(BaseModel):
    keyword: str = Field(
        ...,
        min_length=1,
        description="ê²€ìƒ‰ í‚¤ì›Œë“œ. ì—¬ëŸ¬ ê°œ ì…ë ¥ ì‹œ ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ (ì˜ˆ: AI, ì¸ê³µì§€ëŠ¥, ì¼ë³¸ ê²½ì œ)",
    )
    start_date: Optional[str] = Field(None, description="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    end_date: Optional[str] = Field(None, description="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    sort_by: Literal["sim", "date"] = Field("sim", description="ì •ë ¬: sim=ê´€ë ¨ë„ìˆœ, date=ìµœì‹ ìˆœ (ë„¤ì´ë²„ ì „ìš©)")
    use_relevance_filter: bool = Field(True, description="ì œëª©+ìš”ì•½ ê¸°ì¤€ ê´€ë ¨ë„ë¡œ ìƒìœ„ë§Œ ì„ ì • (ë„¤ì´ë²„ ì „ìš©)")
    provider: Literal["naver", "google"] = Field(
        "naver",
        description="ë‰´ìŠ¤ ì œê³µì: naver=ë„¤ì´ë²„ ë‰´ìŠ¤, google=Google News RSS",
    )


class NewsSearchResponse(BaseModel):
    keyword: str = ""  # ë‹¨ì¼ í‚¤ì›Œë“œì¼ ë•Œì™€ í•˜ìœ„ í˜¸í™˜
    keywords: List[str] = Field(default_factory=list, description="ê²€ìƒ‰ì— ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡")
    period: str
    news_count: int
    news: List[NewsSearchItem]
    slack_sent: bool
    message: str


class ResearchSearchItem(BaseModel):
    title: str
    link: str
    snippet: str
    matched_keyword: str = Field("", description="ì´ ê²°ê³¼ê°€ ê²€ìƒ‰ëœ í‚¤ì›Œë“œ (ì—¬ëŸ¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ í‘œì‹œ)")


class ResearchSearchRequest(BaseModel):
    keyword: str = Field(
        ...,
        min_length=1,
        description="ê²€ìƒ‰ í‚¤ì›Œë“œ. ì—¬ëŸ¬ ê°œ ì…ë ¥ ì‹œ ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ (ì˜ˆ: OECD AI, WHO vaccine)",
    )
    language: Optional[str] = Field(
        None,
        description="ê²€ìƒ‰ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: en, ko, ja, vi). ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ Google ê¸°ë³¸ê°’ ì‚¬ìš©",
    )
    max_results: int = Field(
        30,
        ge=1,
        le=30,
        description="ê°€ì ¸ì˜¬ ìµœëŒ€ ê²°ê³¼ ìˆ˜ (1~30, í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìˆ˜ì§‘)",
    )
    start_date: Optional[str] = Field(None, description="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD). end_dateì™€ í•¨ê»˜ ì“°ë©´ í•´ë‹¹ ê¸°ê°„ìœ¼ë¡œ ì œí•œ")
    end_date: Optional[str] = Field(None, description="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD). start_dateì™€ í•¨ê»˜ ì“°ë©´ í•´ë‹¹ ê¸°ê°„ìœ¼ë¡œ ì œí•œ")
    date_restrict: Optional[str] = Field(
        None,
        description="ê¸°ê°„ ì œí•œ(ë‚ ì§œ ë¯¸ì§€ì • ì‹œ): d1(1ì¼), w1(1ì£¼), m1(1ê°œì›”), y1(1ë…„). ì—†ìœ¼ë©´ ì „ì²´ ê¸°ê°„",
    )


class ResearchSearchResponse(BaseModel):
    keyword: str = ""
    keywords: List[str] = Field(default_factory=list, description="ê²€ìƒ‰ì— ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡")
    total_results: int
    items: List[ResearchSearchItem]
    message: str


def _redact_secrets(text: str) -> str:
    """ë¡œê·¸/ì—ëŸ¬ ë©”ì‹œì§€ì— API í‚¤Â·ë¹„ë°€ê°’ì´ ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤."""
    if not text:
        return text
    s = text
    # key=... (API í‚¤), cx=... (CSE ID), client_secret=..., URL ë‚´ í† í° ë“± ë§ˆìŠ¤í‚¹
    s = re.sub(r"\bkey=[^&\s]+", "key=***", s, flags=re.IGNORECASE)
    s = re.sub(r"\bcx=[^&\s]+", "cx=***", s, flags=re.IGNORECASE)
    s = re.sub(r"\bclient_secret=[^&\s]+", "client_secret=***", s, flags=re.IGNORECASE)
    s = re.sub(r"X-Naver-Client-Secret[:\s]*[^\s]+", "X-Naver-Client-Secret: ***", s, flags=re.IGNORECASE)
    s = re.sub(r"hooks\.slack\.com/services/[^\s]+", "hooks.slack.com/services/***", s, flags=re.IGNORECASE)
    return s


def parse_keywords(raw: str) -> List[str]:
    """ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì—ì„œ í‚¤ì›Œë“œ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ê³µë°± ì œê±° í›„ ë¹ˆ í•­ëª© ì œì™¸."""
    if not raw or not raw.strip():
        return []
    parts = re.split(r"[\n,]+", raw)
    return [p.strip() for p in parts if p.strip()]


# ë¶ˆìš©ì–´ ëª©ë¡ (í•œêµ­ì–´ ì¡°ì‚¬, ì ‘ì†ì‚¬ ë“±)
STOP_WORDS = {
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ì™€", "ê³¼", "ë„", "ë¡œ", "ìœ¼ë¡œ",
    "ì—ì„œ", "ì—ê²Œ", "í•œí…Œ", "ê»˜", "ë”", "ë§Œ", "ê¹Œì§€", "ë¶€í„°", "ì¡°ì°¨", "ë§ˆì €",
    "ê·¸", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", "ê·¸ëŸ°", "ì´ëŸ°", "ì €ëŸ°", "ê·¸ë ‡ê²Œ", "ì´ë ‡ê²Œ", "ì €ë ‡ê²Œ",
    "ê·¸ë¦¬ê³ ", "ë˜í•œ", "ë˜", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ",
    "ìˆë‹¤", "ì—†ë‹¤", "ë˜ë‹¤", "í•˜ë‹¤", "ì´ë‹¤", "ì•„ë‹ˆë‹¤", "ê°™ë‹¤", "ë‹¤ë¥´ë‹¤"
}


def get_korea_time() -> datetime:
    """í•œêµ­ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(KST)


def extract_keywords(text: str, top_n: int = 5) -> List[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # êµ¬ë‘ì  ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # ê³µë°±ìœ¼ë¡œ ë‹¨ì–´ ë¶„ë¦¬
    words = text.split()
    
    # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ 2 ì´ìƒì¸ ë‹¨ì–´ë§Œ ì„ íƒ
    filtered_words = [
        word for word in words 
        if word not in STOP_WORDS and len(word) >= 2
    ]
    
    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    word_counts = Counter(filtered_words)
    
    # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_words = [word for word, count in word_counts.most_common(top_n)]
    
    return top_words


def validate_api_keys() -> Tuple[str, str]:
    """ë„¤ì´ë²„ API í‚¤ë¥¼ ê²€ì¦í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        logger.error("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise HTTPException(
            status_code=500,
            detail="ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRET í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        )
    
    return client_id, client_secret


def validate_date_format(date_str: str) -> bool:
    """ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        datetime.strptime(date_str, "%Y-%m-%d")
        return True
    except ValueError:
        return False


def _relevance_score(keyword: str, title: str, description: str) -> int:
    """ì œëª©Â·ìš”ì•½ì—ì„œ í‚¤ì›Œë“œ ì¶œí˜„ íšŸìˆ˜ë¡œ ê´€ë ¨ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì œëª© ê°€ì¤‘ì¹˜ 2ë°°."""
    title_clean = (title or "").strip()
    desc_clean = (description or "").strip()
    kw = keyword.strip()
    if not kw:
        return 0
    # ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ 2, ìš”ì•½ì€ 1
    score = title_clean.count(kw) * 2 + desc_clean.count(kw)
    return score


def _fetch_research_page(
    keyword: str,
    language: Optional[str],
    start_index: int,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    date_restrict: Optional[str] = None,
) -> List[ResearchSearchItem]:
    """Google Custom Search API 1íšŒ í˜¸ì¶œ. start_indexëŠ” 1, 11, 21 ë“±(í˜ì´ì§€ë„¤ì´ì…˜)."""
    url = "https://www.googleapis.com/customsearch/v1"
    params: Dict[str, str] = {
        "key": GOOGLE_API_KEY,
        "cx": GOOGLE_CSE_ID,
        "q": keyword,
        "num": "10",
        "start": str(start_index),
    }
    if language:
        params["lr"] = f"lang_{language}"
    if start_date and end_date and validate_date_format(start_date) and validate_date_format(end_date):
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        if start_dt <= end_dt:
            params["sort"] = f"date:r:{start_date.replace('-', '')}:{end_date.replace('-', '')}"
    elif date_restrict:
        params["dateRestrict"] = date_restrict

    response = requests.get(url, params=params, timeout=10)
    response.raise_for_status()
    data = response.json()
    items_data = data.get("items", []) or []
    return [
        ResearchSearchItem(
            title=item.get("title", ""),
            link=item.get("link", ""),
            snippet=item.get("snippet", ""),
            matched_keyword=keyword,
        )
        for item in items_data
    ]


def get_research_results(
    keywords: List[str],
    language: Optional[str] = None,
    max_results_per_keyword: int = 30,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    date_restrict: Optional[str] = None,
) -> List[ResearchSearchItem]:
    """
    Google Custom Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ì†Œ/ì •ë¶€/êµ­ì œê¸°êµ¬ ë“±ì˜ ìë£Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ì£¼ë©´ í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰í•œ ë’¤ ê²°ê³¼ë¥¼ í•©ì³ ë°˜í™˜í•˜ë©°, ìµœëŒ€ 30ê°œê¹Œì§€ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    if not GOOGLE_CSE_ID or not GOOGLE_API_KEY:
        logger.error("Google Custom Search API í‚¤ ë˜ëŠ” CSE IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise HTTPException(
            status_code=500,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ë ¤ë©´ GOOGLE_CSE_IDì™€ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
        )

    if not keywords:
        raise HTTPException(
            status_code=400,
            detail="ê²€ìƒ‰ í‚¤ì›Œë“œëŠ” ë¹„ì–´ ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        )

    if start_date and end_date and (not validate_date_format(start_date) or not validate_date_format(end_date)):
        raise HTTPException(
            status_code=400,
            detail="ì‹œì‘/ì¢…ë£Œ ë‚ ì§œëŠ” YYYY-MM-DD í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
        )
    if start_date and end_date:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        if start_dt > end_dt:
            raise HTTPException(status_code=400, detail="ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    try:
        research_items: List[ResearchSearchItem] = []
        for kw in keywords:
            collected: List[ResearchSearchItem] = []
            for start_index in (1, 11, 21):
                if len(collected) >= max_results_per_keyword:
                    break
                logger.info(
                    f"Google Custom Search í˜¸ì¶œ: keyword={kw}, start={start_index}, date_restrict={date_restrict}, start_date={start_date}, end_date={end_date}"
                )
                page = _fetch_research_page(
                    kw, language, start_index, start_date, end_date, date_restrict
                )
                collected.extend(page)
                if len(page) < 10:
                    break
            research_items.extend(collected[:max_results_per_keyword])

        logger.info(f"Google Custom Search ê²°ê³¼: ì´ {len(research_items)}ê°œ (í‚¤ì›Œë“œ {len(keywords)}ê°œ)")
        return research_items

    except HTTPException:
        raise
    except requests.exceptions.Timeout:
        logger.error("Google Custom Search í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        raise HTTPException(
            status_code=504,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ API í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except requests.exceptions.HTTPError as e:
        logger.error("Google Custom Search HTTP ì˜¤ë¥˜: %s - %s", e.response.status_code, _redact_secrets(e.response.text or ""))
        if e.response.status_code == 403:
            raise HTTPException(
                status_code=403,
                detail=(
                    "Custom Search API ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤(403). "
                    "ì´ APIëŠ” ë¬´ë£Œ í• ë‹¹ëŸ‰(ì¼ 100íšŒ)ì„ ì“°ë”ë¼ë„ í”„ë¡œì íŠ¸ì— ê²°ì œ(ë¹Œë§) ê³„ì •ì´ ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. "
                    "ê²°ì œ ê³„ì •ì´ ì—†ê±°ë‚˜ ì‚¬ìš© ì¤‘ì§€ëœ ê²½ìš° ë¦¬ì„œì¹˜ ê²€ìƒ‰ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©°, ë‰´ìŠ¤ ê²€ìƒ‰(ë„¤ì´ë²„/Google News)ë§Œ ì´ìš©í•´ ì£¼ì„¸ìš”."
                ),
            )
        raise HTTPException(
            status_code=500,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ HTTP ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: " + str(e.response.status_code),
        )
    except requests.exceptions.RequestException as e:
        logger.error("Google Custom Search ìš”ì²­ ì˜¤ë¥˜: %s", _redact_secrets(str(e)))
        raise HTTPException(
            status_code=500,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )
    except Exception as e:
        logger.error("ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", _redact_secrets(str(e)), exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )


def get_google_news(
    keyword: str,
    max_results: int = 30,
) -> List[NewsSearchItem]:
    """
    Google News RSSë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸€ë¡œë²Œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - ê²€ìƒ‰ì€ Google News ê¸°ì¤€ìœ¼ë¡œ ì œëª©Â·ìš”ì•½ì— ëŒ€í•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
    - ë‚ ì§œ í•„í„°(start_date/end_date)ëŠ” ì§ì ‘ ì ìš©í•˜ì§€ ì•Šê³ , Google Newsì˜ ìµœì‹  ì •ë ¬ì— ë”°ë¦…ë‹ˆë‹¤.
    """
    try:
        if not keyword.strip():
            raise HTTPException(
                status_code=400,
                detail="ê²€ìƒ‰ í‚¤ì›Œë“œëŠ” ë¹„ì–´ ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        url = "https://news.google.com/rss/search"
        params = {
            "q": keyword,
            "hl": GOOGLE_NEWS_HL,
            "gl": GOOGLE_NEWS_GL,
            "ceid": GOOGLE_NEWS_CEID,
        }

        logger.info(
            f"Google News RSS í˜¸ì¶œ: keyword={keyword}, hl={GOOGLE_NEWS_HL}, gl={GOOGLE_NEWS_GL}, ceid={GOOGLE_NEWS_CEID}"
        )

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        root = ET.fromstring(response.text)
        channel = root.find("channel")
        if channel is None:
            logger.warning("Google News RSS: channel ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        items = channel.findall("item")
        news_items: List[NewsSearchItem] = []

        for item in items[:max_results]:
            title_elem = item.find("title")
            link_elem = item.find("link")
            pub_date_elem = item.find("pubDate")

            raw_title = title_elem.text if title_elem is not None else ""
            title = re.sub(r"<[^>]+>", "", raw_title or "")

            link = link_elem.text if link_elem is not None else ""

            pub_date_raw = pub_date_elem.text if pub_date_elem is not None else ""
            if pub_date_raw:
                try:
                    # ì˜ˆ: Tue, 04 Feb 2025 10:00:00 GMT
                    date_obj = datetime.strptime(
                        pub_date_raw.strip(), "%a, %d %b %Y %H:%M:%S %Z"
                    )
                    # Googleì€ ë³´í†µ GMT ê¸°ì¤€, í•œêµ­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
                    date_obj = date_obj.replace(tzinfo=pytz.UTC).astimezone(KST)
                    formatted_date = date_obj.strftime("%Y-%m-%d")
                except Exception as e:
                    logger.warning(
                        f"Google News ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {pub_date_raw}, ì˜¤ë¥˜: {str(e)}"
                    )
                    formatted_date = get_korea_time().strftime("%Y-%m-%d")
            else:
                formatted_date = get_korea_time().strftime("%Y-%m-%d")

            news_items.append(
                NewsSearchItem(
                    title=title,
                    link=link,
                    pubDate=formatted_date,
                )
            )

        logger.info(f"Google News RSS ê²€ìƒ‰ ì™„ë£Œ: {len(news_items)}ê°œ ê²°ê³¼")
        return news_items

    except HTTPException:
        raise
    except requests.exceptions.Timeout:
        logger.error("Google News RSS í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        raise HTTPException(
            status_code=504,
            detail="Google News RSS í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except requests.exceptions.HTTPError as e:
        logger.error("Google News RSS HTTP ì˜¤ë¥˜: %s - %s", e.response.status_code, _redact_secrets(e.response.text or ""))
        raise HTTPException(
            status_code=500,
            detail="Google News RSS í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: " + str(e.response.status_code),
        )
    except requests.exceptions.RequestException as e:
        logger.error("Google News RSS ìš”ì²­ ì˜¤ë¥˜: %s", _redact_secrets(str(e)))
        raise HTTPException(
            status_code=500,
            detail="Google News RSS í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )
    except Exception as e:
        logger.error("Google News RSS ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", _redact_secrets(str(e)), exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="Google News RSS í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )


def get_naver_news(
    keyword: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    max_results: int = 10,
    sort_by: str = "sim",
    use_relevance_filter: bool = True,
) -> List[NewsSearchItem]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - ê²€ìƒ‰ì€ ë„¤ì´ë²„ API ê¸°ì¤€ìœ¼ë¡œ ì œëª©Â·ìš”ì•½(description)ì—ì„œë§Œ ì´ë£¨ì–´ì§€ë©°, ë³¸ë¬¸ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - use_relevance_filter=Trueì´ë©´ APIì—ì„œ ë” ë§ì´ ë°›ì•„ì˜¨ ë’¤, ì œëª©+ìš”ì•½ ê¸°ì¤€ ê´€ë ¨ë„ ì ìˆ˜ë¡œ ìƒìœ„ë§Œ ì„ ì •í•©ë‹ˆë‹¤.
    """
    try:
        client_id, client_secret = validate_api_keys()
        
        # ë‚ ì§œ ê²€ì¦
        if start_date and not validate_date_format(start_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì‹œì‘ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {start_date})"
            )
        
        if end_date and not validate_date_format(end_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {end_date})"
            )
        
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret
        }
        # ê´€ë ¨ë„ í•„í„° ì‚¬ìš© ì‹œ í›„ë³´ë¥¼ ë” ë°›ì•„ì„œ ìš°ë¦¬ê°€ ìƒìœ„ë§Œ ì„ ì •
        request_display = min(30, 100) if use_relevance_filter else min(max_results, 100)
        params = {
            "query": keyword,
            "display": request_display,
            "sort": sort_by,  # sim=ê´€ë ¨ë„ìˆœ, date=ìµœì‹ ìˆœ
            "start": 1
        }
        
        logger.info(f"ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ: keyword={keyword}, start_date={start_date}, end_date={end_date}, sort={sort_by}, relevance_filter={use_relevance_filter}")
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        candidates: List[Tuple[int, NewsSearchItem]] = []
        for item in data.get("items", []):
            title = re.sub(r'<[^>]+>', '', item.get("title", ""))
            description = re.sub(r'<[^>]+>', '', item.get("description", ""))
            
            pub_date = item.get("pubDate", "")
            if pub_date:
                try:
                    date_obj = datetime.strptime(pub_date.split("+")[0].strip(), "%a, %d %b %Y %H:%M:%S")
                    date_obj = date_obj.replace(tzinfo=pytz.UTC).astimezone(KST)
                    formatted_date = date_obj.strftime("%Y-%m-%d")
                except Exception as e:
                    logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {pub_date}, ì˜¤ë¥˜: {str(e)}")
                    formatted_date = get_korea_time().strftime("%Y-%m-%d")
            else:
                formatted_date = get_korea_time().strftime("%Y-%m-%d")
            
            news_item = NewsSearchItem(
                title=title,
                link=item.get("link", ""),
                pubDate=formatted_date
            )
            score = _relevance_score(keyword, title, description) if use_relevance_filter else 0
            candidates.append((score, news_item))
        
        if use_relevance_filter:
            candidates.sort(key=lambda x: -x[0])  # ê´€ë ¨ë„ ì ìˆ˜ ë†’ì€ ìˆœ
        news_items = [item for _, item in candidates[:max_results]]
        
        logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(news_items)}ê°œ ê²°ê³¼ (ê´€ë ¨ë„ í•„í„°={use_relevance_filter})")
        return news_items
    
    except HTTPException:
        raise
    except requests.exceptions.Timeout:
        logger.error("ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        raise HTTPException(
            status_code=504,
            detail="ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except requests.exceptions.HTTPError as e:
        logger.error("ë„¤ì´ë²„ ë‰´ìŠ¤ API HTTP ì˜¤ë¥˜: %s - %s", e.response.status_code, _redact_secrets(e.response.text or ""))
        if e.response.status_code == 401:
            raise HTTPException(
                status_code=401,
                detail="ë„¤ì´ë²„ API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        elif e.response.status_code == 429:
            raise HTTPException(
                status_code=429,
                detail="API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            raise HTTPException(
                status_code=500,
                detail="ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: " + str(e.response.status_code),
            )
    except requests.exceptions.RequestException as e:
        logger.error("ë„¤ì´ë²„ ë‰´ìŠ¤ API ìš”ì²­ ì˜¤ë¥˜: %s", _redact_secrets(str(e)))
        raise HTTPException(
            status_code=500,
            detail="ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )
    except Exception as e:
        logger.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: %s", _redact_secrets(str(e)), exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        )


def send_slack_notification(keyword: str, news_items: List[NewsSearchItem], period: str) -> bool:
    """
    Slack Webhookì„ í†µí•´ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    webhook_url = os.getenv("SLACK_WEBHOOK_URL")
    
    if not webhook_url:
        logger.warning("SLACK_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        news_text = "\n".join([
            f"{i+1}. " + (f"[{item.keyword}] " if getattr(item, 'keyword', None) else "") + f"<{item.link}|{item.title}> ({item.pubDate})"
            for i, item in enumerate(news_items)
        ])
        
        message = {
            "text": f"ğŸ“° ë‰´ìŠ¤ ì•Œë¦¼: '{keyword}'",
            "blocks": [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": f"ğŸ“° ë‰´ìŠ¤ ì•Œë¦¼: '{keyword}'"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ê¸°ê°„:* {period}\n*ê²€ìƒ‰ ê²°ê³¼:* {len(news_items)}ê°œ"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ë‰´ìŠ¤ ëª©ë¡:*\n{news_text}"
                    }
                }
            ]
        }
        
        logger.info(f"Slack ì•Œë¦¼ ì „ì†¡ ì‹œë„: keyword={keyword}, news_count={len(news_items)}")
        response = requests.post(webhook_url, json=message, timeout=10)
        response.raise_for_status()
        logger.info("Slack ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
        return True
    except requests.exceptions.Timeout:
        logger.error("Slack Webhook í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        return False
    except requests.exceptions.HTTPError as e:
        logger.error("Slack Webhook HTTP ì˜¤ë¥˜: %s - %s", e.response.status_code, _redact_secrets(e.response.text or ""))
        return False
    except requests.exceptions.RequestException as e:
        logger.error("Slack Webhook ìš”ì²­ ì˜¤ë¥˜: %s", _redact_secrets(str(e)))
        return False
    except Exception as e:
        logger.error("Slack ì•Œë¦¼ ì „ì†¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", _redact_secrets(str(e)), exc_info=True)
        return False


# ì˜ˆì‹œ ê°€ì§œ ë‰´ìŠ¤ ë°ì´í„°
FAKE_NEWS_DATABASE = {
    "ì •ì¹˜": [
        "ì •ì¹˜ì¸ ë¹„ë¦¬ í­ë¡œ, ì¶©ê²©ì ì¸ ì§„ì‹¤ ê³µê°œ",
        "ì •ì¹˜ê¶Œ ëŒ€ê·œëª¨ ë¶€íŒ¨ ìŠ¤ìº”ë“¤ ë°œìƒ",
        "ì •ì¹˜ ê°œí˜ì„ ìœ„í•œ ìƒˆë¡œìš´ ë²•ì•ˆ í†µê³¼"
    ],
    "ê²½ì œ": [
        "ê²½ì œ ìœ„ê¸°ë¡œ ì¸í•œ ëŒ€ê·œëª¨ ì‹¤ì—… ë°œìƒ",
        "ê²½ì œ ì„±ì¥ë¥  ì—­ëŒ€ ìµœê³ ì¹˜ ê¸°ë¡",
        "ê²½ì œ ì •ì±… ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì‹œì¥ í˜¼ë€"
    ],
    "ê¸°ìˆ ": [
        "ê¸°ìˆ  í˜ì‹ ìœ¼ë¡œ ì¸í•œ ì¼ìë¦¬ ëŒ€ëŸ‰ ê°ì†Œ",
        "ê¸°ìˆ  ê¸°ì—…ì˜ ë…ì  ì‹¬í™” ìš°ë ¤",
        "ê¸°ìˆ  ë°œì „ì´ ê°€ì ¸ì˜¬ ë¯¸ë˜ì˜ ë³€í™”"
    ],
    "ê±´ê°•": [
        "ê±´ê°• ê´€ë¦¬ì˜ ìƒˆë¡œìš´ ë°©ë²• ë°œê²¬",
        "ê±´ê°• ì‹í’ˆì˜ íš¨ê³¼ ì…ì¦",
        "ê±´ê°• ê²€ì§„ ê²°ê³¼ ì¶©ê²©ì ì¸ ë°œê²¬"
    ],
    "í™˜ê²½": [
        "í™˜ê²½ ì˜¤ì—¼ìœ¼ë¡œ ì¸í•œ ìƒíƒœê³„ íŒŒê´´",
        "í™˜ê²½ ë³´í˜¸ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì •ì±… ë°œí‘œ",
        "í™˜ê²½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê¸´ê¸‰ ì¡°ì¹˜"
    ]
}


@app.get("/", response_class=HTMLResponse)
def root(request: Request):
    """
    í™ˆí˜ì´ì§€ - ë‰´ìŠ¤ ê²€ìƒ‰ í¼
    """
    logger.info("í™ˆí˜ì´ì§€ ì ‘ì†")
    return templates.TemplateResponse(request, "index.html")


@app.get("/health")
def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": get_korea_time().isoformat()}


@app.get("/news", response_model=NewsResponse)
def get_news(keyword: str = Query(..., description="ê²€ìƒ‰í•  í‚¤ì›Œë“œ")):
    """
    ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê°€ì§œ ë‰´ìŠ¤ ì œëª© 3ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # í‚¤ì›Œë“œê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ê²½ìš° í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ ë°˜í™˜
    if keyword in FAKE_NEWS_DATABASE:
        news_items = [
            NewsItem(title=title, keyword=keyword)
            for title in FAKE_NEWS_DATABASE[keyword]
        ]
    else:
        # í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì˜ˆì‹œ ë‰´ìŠ¤ ìƒì„±
        news_items = [
            NewsItem(title=f"{keyword} ê´€ë ¨ ì¶©ê²©ì ì¸ ì†Œì‹ ì „í•´ì ¸", keyword=keyword),
            NewsItem(title=f"{keyword}ë¡œ ì¸í•œ íŒŒì¥ ê³„ì† í™•ì‚°", keyword=keyword),
            NewsItem(title=f"{keyword}ì— ëŒ€í•œ ìƒˆë¡œìš´ ì‚¬ì‹¤ ë°í˜€ì ¸", keyword=keyword)
        ]
    
    return NewsResponse(keyword=keyword, news=news_items)


@app.post("/extract-keywords", response_model=KeywordResponse)
def extract_keywords_api(request: TextRequest = Body(...)):
    """
    í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì¤‘ìš”í•œ ë‹¨ì–´ 5ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    keywords = extract_keywords(request.text, top_n=5)
    
    return KeywordResponse(
        keywords=keywords,
        count=len(keywords)
    )


@app.post("/news/search", response_model=NewsSearchResponse)
def search_news(request: NewsSearchRequest = Body(...)):
    """
    ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  Slack ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
    - provider="naver": ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ì‚¬ìš©
    - provider="google": Google News RSS ì‚¬ìš©
    """
    try:
        # ë‚ ì§œ ê¸°ë³¸ê°’ ì„¤ì • (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        korea_now = get_korea_time()
        
        if not request.end_date:
            end_date = korea_now.strftime("%Y-%m-%d")
        else:
            end_date = request.end_date
        
        if not request.start_date:
            start_date = (korea_now - timedelta(days=7)).strftime("%Y-%m-%d")
        else:
            start_date = request.start_date
        
        # ë‚ ì§œ ê²€ì¦
        if not validate_date_format(start_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì‹œì‘ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {start_date})"
            )
        
        if not validate_date_format(end_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {end_date})"
            )
        
        # ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìœ¼ë©´ ì˜¤ë¥˜
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        if start_dt > end_dt:
            raise HTTPException(
                status_code=400,
                detail="ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        keywords = parse_keywords(request.keyword)
        if not keywords:
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        keyword_display = ", ".join(keywords)

        logger.info(
            f"ë‰´ìŠ¤ ê²€ìƒ‰ ìš”ì²­: keywords={keywords}, start_date={start_date}, end_date={end_date}, provider={request.provider}"
        )

        # í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰ í›„ í•©ì¹¨ (ê° ê¸°ì‚¬ì— keyword íƒœê·¸)
        news_items: List[NewsSearchItem] = []
        for kw in keywords:
            if request.provider == "naver":
                items = get_naver_news(
                    keyword=kw,
                    start_date=start_date,
                    end_date=end_date,
                    max_results=10,
                    sort_by=request.sort_by,
                    use_relevance_filter=request.use_relevance_filter,
                )
            else:
                items = get_google_news(keyword=kw, max_results=30)
            for item in items:
                news_items.append(
                    NewsSearchItem(
                        title=item.title,
                        link=item.link,
                        pubDate=item.pubDate,
                        keyword=kw,
                    )
                )

        period = f"{start_date} ~ {end_date}"
        slack_sent = send_slack_notification(keyword_display, news_items, period)

        if slack_sent:
            message = f"Slackìœ¼ë¡œ {len(news_items)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì „ì†¡í–ˆìŠµë‹ˆë‹¤"
        else:
            message = "Slack ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. SLACK_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: keywords={keywords}, news_count={len(news_items)}, slack_sent={slack_sent}")

        return NewsSearchResponse(
            keyword=keyword_display,
            keywords=keywords,
            period=period,
            news_count=len(news_items),
            news=news_items,
            slack_sent=slack_sent,
            message=message,
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", _redact_secrets(str(e)), exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


@app.post("/research/search", response_model=ResearchSearchResponse)
def search_research(request: ResearchSearchRequest = Body(...)):
    """
    ì—°êµ¬ì†Œ/ì •ë¶€/êµ­ì œê¸°êµ¬ ë“±ì˜ ìë£Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œëŠ” ì‰¼í‘œ/ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—¬ëŸ¬ ê°œ ì…ë ¥ ê°€ëŠ¥í•˜ë©°, í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ë¥¼ í•©ì³ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        keywords = parse_keywords(request.keyword)
        if not keywords:
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        logger.info(
            f"ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ìš”ì²­: keywords={keywords}, language={request.language}, max_results={request.max_results}"
        )

        items = get_research_results(
            keywords=keywords,
            language=request.language,
            max_results_per_keyword=request.max_results,
            start_date=request.start_date,
            end_date=request.end_date,
            date_restrict=request.date_restrict,
        )

        message = (
            f"{len(items)}ê°œì˜ ì—°êµ¬/ì •ë¶€ ìë£Œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤ (í‚¤ì›Œë“œ {len(keywords)}ê°œ)."
            if items
            else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        )
        keyword_display = ", ".join(keywords)

        return ResearchSearchResponse(
            keyword=keyword_display,
            keywords=keywords,
            total_results=len(items),
            items=items,
            message=message,
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error("ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: %s", _redact_secrets(str(e)), exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="ì—°êµ¬/ì •ë¶€ ìë£Œ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )
