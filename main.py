from fastapi import FastAPI, Query, Body, HTTPException, Request
from fastapi.responses import HTMLResponse
from starlette.templating import Jinja2Templates
from typing import List, Optional, Tuple, Dict, Literal
from pydantic import BaseModel, Field
import re
from collections import Counter
import os
import logging
from datetime import datetime, timedelta
import requests
from dotenv import load_dotenv
import pytz

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

app = FastAPI(title="ë‰´ìŠ¤ ê²€ìƒ‰ ë° Slack ì•Œë¦¼ ì‹œìŠ¤í…œ")

# Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")


class NewsItem(BaseModel):
    title: str
    keyword: str


class NewsResponse(BaseModel):
    keyword: str
    news: List[NewsItem]


class TextRequest(BaseModel):
    text: str


class KeywordResponse(BaseModel):
    keywords: List[str]
    count: int


class NewsSearchItem(BaseModel):
    title: str
    link: str
    pubDate: str


class NewsSearchRequest(BaseModel):
    keyword: str = Field(..., min_length=1, description="ê²€ìƒ‰ í‚¤ì›Œë“œ")
    start_date: Optional[str] = Field(None, description="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    end_date: Optional[str] = Field(None, description="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    sort_by: Literal["sim", "date"] = Field("sim", description="ì •ë ¬: sim=ê´€ë ¨ë„ìˆœ, date=ìµœì‹ ìˆœ")
    use_relevance_filter: bool = Field(True, description="ì œëª©+ìš”ì•½ ê¸°ì¤€ ê´€ë ¨ë„ë¡œ ìƒìœ„ë§Œ ì„ ì •")


class NewsSearchResponse(BaseModel):
    keyword: str
    period: str
    news_count: int
    news: List[NewsSearchItem]
    slack_sent: bool
    message: str


# ë¶ˆìš©ì–´ ëª©ë¡ (í•œêµ­ì–´ ì¡°ì‚¬, ì ‘ì†ì‚¬ ë“±)
STOP_WORDS = {
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ì™€", "ê³¼", "ë„", "ë¡œ", "ìœ¼ë¡œ",
    "ì—ì„œ", "ì—ê²Œ", "í•œí…Œ", "ê»˜", "ë”", "ë§Œ", "ê¹Œì§€", "ë¶€í„°", "ì¡°ì°¨", "ë§ˆì €",
    "ê·¸", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", "ê·¸ëŸ°", "ì´ëŸ°", "ì €ëŸ°", "ê·¸ë ‡ê²Œ", "ì´ë ‡ê²Œ", "ì €ë ‡ê²Œ",
    "ê·¸ë¦¬ê³ ", "ë˜í•œ", "ë˜", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ",
    "ìˆë‹¤", "ì—†ë‹¤", "ë˜ë‹¤", "í•˜ë‹¤", "ì´ë‹¤", "ì•„ë‹ˆë‹¤", "ê°™ë‹¤", "ë‹¤ë¥´ë‹¤"
}


def get_korea_time() -> datetime:
    """í•œêµ­ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(KST)


def extract_keywords(text: str, top_n: int = 5) -> List[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # êµ¬ë‘ì  ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # ê³µë°±ìœ¼ë¡œ ë‹¨ì–´ ë¶„ë¦¬
    words = text.split()
    
    # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ 2 ì´ìƒì¸ ë‹¨ì–´ë§Œ ì„ íƒ
    filtered_words = [
        word for word in words 
        if word not in STOP_WORDS and len(word) >= 2
    ]
    
    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    word_counts = Counter(filtered_words)
    
    # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_words = [word for word, count in word_counts.most_common(top_n)]
    
    return top_words


def validate_api_keys() -> Tuple[str, str]:
    """ë„¤ì´ë²„ API í‚¤ë¥¼ ê²€ì¦í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        logger.error("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise HTTPException(
            status_code=500,
            detail="ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRET í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        )
    
    return client_id, client_secret


def validate_date_format(date_str: str) -> bool:
    """ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        datetime.strptime(date_str, "%Y-%m-%d")
        return True
    except ValueError:
        return False


def _relevance_score(keyword: str, title: str, description: str) -> int:
    """ì œëª©Â·ìš”ì•½ì—ì„œ í‚¤ì›Œë“œ ì¶œí˜„ íšŸìˆ˜ë¡œ ê´€ë ¨ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì œëª© ê°€ì¤‘ì¹˜ 2ë°°."""
    title_clean = (title or "").strip()
    desc_clean = (description or "").strip()
    kw = keyword.strip()
    if not kw:
        return 0
    # ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ 2, ìš”ì•½ì€ 1
    score = title_clean.count(kw) * 2 + desc_clean.count(kw)
    return score


def get_naver_news(
    keyword: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    max_results: int = 10,
    sort_by: str = "sim",
    use_relevance_filter: bool = True,
) -> List[NewsSearchItem]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - ê²€ìƒ‰ì€ ë„¤ì´ë²„ API ê¸°ì¤€ìœ¼ë¡œ ì œëª©Â·ìš”ì•½(description)ì—ì„œë§Œ ì´ë£¨ì–´ì§€ë©°, ë³¸ë¬¸ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - use_relevance_filter=Trueì´ë©´ APIì—ì„œ ë” ë§ì´ ë°›ì•„ì˜¨ ë’¤, ì œëª©+ìš”ì•½ ê¸°ì¤€ ê´€ë ¨ë„ ì ìˆ˜ë¡œ ìƒìœ„ë§Œ ì„ ì •í•©ë‹ˆë‹¤.
    """
    try:
        client_id, client_secret = validate_api_keys()
        
        # ë‚ ì§œ ê²€ì¦
        if start_date and not validate_date_format(start_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì‹œì‘ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {start_date})"
            )
        
        if end_date and not validate_date_format(end_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {end_date})"
            )
        
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret
        }
        # ê´€ë ¨ë„ í•„í„° ì‚¬ìš© ì‹œ í›„ë³´ë¥¼ ë” ë°›ì•„ì„œ ìš°ë¦¬ê°€ ìƒìœ„ë§Œ ì„ ì •
        request_display = min(30, 100) if use_relevance_filter else min(max_results, 100)
        params = {
            "query": keyword,
            "display": request_display,
            "sort": sort_by,  # sim=ê´€ë ¨ë„ìˆœ, date=ìµœì‹ ìˆœ
            "start": 1
        }
        
        logger.info(f"ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ: keyword={keyword}, start_date={start_date}, end_date={end_date}, sort={sort_by}, relevance_filter={use_relevance_filter}")
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        candidates: List[Tuple[int, NewsSearchItem]] = []
        for item in data.get("items", []):
            title = re.sub(r'<[^>]+>', '', item.get("title", ""))
            description = re.sub(r'<[^>]+>', '', item.get("description", ""))
            
            pub_date = item.get("pubDate", "")
            if pub_date:
                try:
                    date_obj = datetime.strptime(pub_date.split("+")[0].strip(), "%a, %d %b %Y %H:%M:%S")
                    date_obj = date_obj.replace(tzinfo=pytz.UTC).astimezone(KST)
                    formatted_date = date_obj.strftime("%Y-%m-%d")
                except Exception as e:
                    logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {pub_date}, ì˜¤ë¥˜: {str(e)}")
                    formatted_date = get_korea_time().strftime("%Y-%m-%d")
            else:
                formatted_date = get_korea_time().strftime("%Y-%m-%d")
            
            news_item = NewsSearchItem(
                title=title,
                link=item.get("link", ""),
                pubDate=formatted_date
            )
            score = _relevance_score(keyword, title, description) if use_relevance_filter else 0
            candidates.append((score, news_item))
        
        if use_relevance_filter:
            candidates.sort(key=lambda x: -x[0])  # ê´€ë ¨ë„ ì ìˆ˜ ë†’ì€ ìˆœ
        news_items = [item for _, item in candidates[:max_results]]
        
        logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(news_items)}ê°œ ê²°ê³¼ (ê´€ë ¨ë„ í•„í„°={use_relevance_filter})")
        return news_items
    
    except HTTPException:
        raise
    except requests.exceptions.Timeout:
        logger.error("ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        raise HTTPException(
            status_code=504,
            detail="ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except requests.exceptions.HTTPError as e:
        logger.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ API HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
        if e.response.status_code == 401:
            raise HTTPException(
                status_code=401,
                detail="ë„¤ì´ë²„ API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        elif e.response.status_code == 429:
            raise HTTPException(
                status_code=429,
                detail="API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    except requests.exceptions.RequestException as e:
        logger.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ API ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


def send_slack_notification(keyword: str, news_items: List[NewsSearchItem], period: str) -> bool:
    """
    Slack Webhookì„ í†µí•´ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    webhook_url = os.getenv("SLACK_WEBHOOK_URL")
    
    if not webhook_url:
        logger.warning("SLACK_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        news_text = "\n".join([
            f"{i+1}. <{item.link}|{item.title}> ({item.pubDate})"
            for i, item in enumerate(news_items)
        ])
        
        message = {
            "text": f"ğŸ“° ë‰´ìŠ¤ ì•Œë¦¼: '{keyword}'",
            "blocks": [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": f"ğŸ“° ë‰´ìŠ¤ ì•Œë¦¼: '{keyword}'"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ê¸°ê°„:* {period}\n*ê²€ìƒ‰ ê²°ê³¼:* {len(news_items)}ê°œ"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ë‰´ìŠ¤ ëª©ë¡:*\n{news_text}"
                    }
                }
            ]
        }
        
        logger.info(f"Slack ì•Œë¦¼ ì „ì†¡ ì‹œë„: keyword={keyword}, news_count={len(news_items)}")
        response = requests.post(webhook_url, json=message, timeout=10)
        response.raise_for_status()
        logger.info("Slack ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
        return True
    except requests.exceptions.Timeout:
        logger.error("Slack Webhook í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        return False
    except requests.exceptions.HTTPError as e:
        logger.error(f"Slack Webhook HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
        return False
    except requests.exceptions.RequestException as e:
        logger.error(f"Slack Webhook ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"Slack ì•Œë¦¼ ì „ì†¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return False


# ì˜ˆì‹œ ê°€ì§œ ë‰´ìŠ¤ ë°ì´í„°
FAKE_NEWS_DATABASE = {
    "ì •ì¹˜": [
        "ì •ì¹˜ì¸ ë¹„ë¦¬ í­ë¡œ, ì¶©ê²©ì ì¸ ì§„ì‹¤ ê³µê°œ",
        "ì •ì¹˜ê¶Œ ëŒ€ê·œëª¨ ë¶€íŒ¨ ìŠ¤ìº”ë“¤ ë°œìƒ",
        "ì •ì¹˜ ê°œí˜ì„ ìœ„í•œ ìƒˆë¡œìš´ ë²•ì•ˆ í†µê³¼"
    ],
    "ê²½ì œ": [
        "ê²½ì œ ìœ„ê¸°ë¡œ ì¸í•œ ëŒ€ê·œëª¨ ì‹¤ì—… ë°œìƒ",
        "ê²½ì œ ì„±ì¥ë¥  ì—­ëŒ€ ìµœê³ ì¹˜ ê¸°ë¡",
        "ê²½ì œ ì •ì±… ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì‹œì¥ í˜¼ë€"
    ],
    "ê¸°ìˆ ": [
        "ê¸°ìˆ  í˜ì‹ ìœ¼ë¡œ ì¸í•œ ì¼ìë¦¬ ëŒ€ëŸ‰ ê°ì†Œ",
        "ê¸°ìˆ  ê¸°ì—…ì˜ ë…ì  ì‹¬í™” ìš°ë ¤",
        "ê¸°ìˆ  ë°œì „ì´ ê°€ì ¸ì˜¬ ë¯¸ë˜ì˜ ë³€í™”"
    ],
    "ê±´ê°•": [
        "ê±´ê°• ê´€ë¦¬ì˜ ìƒˆë¡œìš´ ë°©ë²• ë°œê²¬",
        "ê±´ê°• ì‹í’ˆì˜ íš¨ê³¼ ì…ì¦",
        "ê±´ê°• ê²€ì§„ ê²°ê³¼ ì¶©ê²©ì ì¸ ë°œê²¬"
    ],
    "í™˜ê²½": [
        "í™˜ê²½ ì˜¤ì—¼ìœ¼ë¡œ ì¸í•œ ìƒíƒœê³„ íŒŒê´´",
        "í™˜ê²½ ë³´í˜¸ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì •ì±… ë°œí‘œ",
        "í™˜ê²½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê¸´ê¸‰ ì¡°ì¹˜"
    ]
}


@app.get("/", response_class=HTMLResponse)
def root(request: Request):
    """
    í™ˆí˜ì´ì§€ - ë‰´ìŠ¤ ê²€ìƒ‰ í¼
    """
    logger.info("í™ˆí˜ì´ì§€ ì ‘ì†")
    return templates.TemplateResponse(request, "index.html")


@app.get("/health")
def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": get_korea_time().isoformat()}


@app.get("/news", response_model=NewsResponse)
def get_news(keyword: str = Query(..., description="ê²€ìƒ‰í•  í‚¤ì›Œë“œ")):
    """
    ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê°€ì§œ ë‰´ìŠ¤ ì œëª© 3ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # í‚¤ì›Œë“œê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ê²½ìš° í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ ë°˜í™˜
    if keyword in FAKE_NEWS_DATABASE:
        news_items = [
            NewsItem(title=title, keyword=keyword)
            for title in FAKE_NEWS_DATABASE[keyword]
        ]
    else:
        # í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì˜ˆì‹œ ë‰´ìŠ¤ ìƒì„±
        news_items = [
            NewsItem(title=f"{keyword} ê´€ë ¨ ì¶©ê²©ì ì¸ ì†Œì‹ ì „í•´ì ¸", keyword=keyword),
            NewsItem(title=f"{keyword}ë¡œ ì¸í•œ íŒŒì¥ ê³„ì† í™•ì‚°", keyword=keyword),
            NewsItem(title=f"{keyword}ì— ëŒ€í•œ ìƒˆë¡œìš´ ì‚¬ì‹¤ ë°í˜€ì ¸", keyword=keyword)
        ]
    
    return NewsResponse(keyword=keyword, news=news_items)


@app.post("/extract-keywords", response_model=KeywordResponse)
def extract_keywords_api(request: TextRequest = Body(...)):
    """
    í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì¤‘ìš”í•œ ë‹¨ì–´ 5ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    keywords = extract_keywords(request.text, top_n=5)
    
    return KeywordResponse(
        keywords=keywords,
        count=len(keywords)
    )


@app.post("/news/search", response_model=NewsSearchResponse)
def search_news(request: NewsSearchRequest = Body(...)):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  Slack ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    try:
        # ë‚ ì§œ ê¸°ë³¸ê°’ ì„¤ì • (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        korea_now = get_korea_time()
        
        if not request.end_date:
            end_date = korea_now.strftime("%Y-%m-%d")
        else:
            end_date = request.end_date
        
        if not request.start_date:
            start_date = (korea_now - timedelta(days=7)).strftime("%Y-%m-%d")
        else:
            start_date = request.start_date
        
        # ë‚ ì§œ ê²€ì¦
        if not validate_date_format(start_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì‹œì‘ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {start_date})"
            )
        
        if not validate_date_format(end_date):
            raise HTTPException(
                status_code=400,
                detail=f"ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì…ë ¥: {end_date})"
            )
        
        # ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìœ¼ë©´ ì˜¤ë¥˜
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        if start_dt > end_dt:
            raise HTTPException(
                status_code=400,
                detail="ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ìš”ì²­: keyword={request.keyword}, start_date={start_date}, end_date={end_date}")
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ì œëª©+ìš”ì•½ ê¸°ì¤€ ê´€ë ¨ë„ ì„ ì • ì˜µì…˜ ì‚¬ìš©)
        news_items = get_naver_news(
            keyword=request.keyword,
            start_date=start_date,
            end_date=end_date,
            max_results=10,
            sort_by=request.sort_by,
            use_relevance_filter=request.use_relevance_filter,
        )
        
        # Slack ì•Œë¦¼ ì „ì†¡
        period = f"{start_date} ~ {end_date}"
        slack_sent = send_slack_notification(request.keyword, news_items, period)
        
        if slack_sent:
            message = f"Slackìœ¼ë¡œ {len(news_items)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì „ì†¡í–ˆìŠµë‹ˆë‹¤"
        else:
            message = "Slack ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. SLACK_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: keyword={request.keyword}, news_count={len(news_items)}, slack_sent={slack_sent}")
        
        return NewsSearchResponse(
            keyword=request.keyword,
            period=period,
            news_count=len(news_items),
            news=news_items,
            slack_sent=slack_sent,
            message=message
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
